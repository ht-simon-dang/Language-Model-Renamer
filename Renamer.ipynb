{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8c08e9",
      "metadata": {
        "id": "5e8c08e9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"unsloth/Qwen2.5-3B-Instruct-bnb-4bit\", device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Qwen2.5-3B-Instruct-bnb-4bit\")\n",
        "\n",
        "print(f\"Model loaded successfully on {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "615b61b9",
      "metadata": {
        "id": "615b61b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def generate_new_name(original_name, tokenizer, model, device=\"cuda\"):\n",
        "    prompt = (f\"Try to identify the name of a song in the following input texts. Only return the song name:'{original_name}'. \"\n",
        "              \"Output only the new name you guess without any additional text.\")\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512, do_sample=True)\n",
        "\n",
        "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa73d1c9",
      "metadata": {
        "id": "fa73d1c9"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/mnt/d/网络下载音乐/\"  # Replace with your folder path\n",
        "\n",
        "# Iterate over files in the folder and rename them based on model output.\n",
        "for filename in os.listdir(folder_path):\n",
        "    original_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Process only files (skip directories)\n",
        "    if os.path.isfile(original_path):\n",
        "        print(f\"Processing file: {filename}\")\n",
        "\n",
        "        # Generate a new file name using the model\n",
        "        new_base_name = generate_new_name(filename, tokenizer, model, device)\n",
        "\n",
        "        # Optionally, preserve the original extension if not included in the generated name.\n",
        "        original_ext = os.path.splitext(filename)[1]\n",
        "        if not new_base_name.endswith(original_ext):\n",
        "            new_base_name += original_ext\n",
        "\n",
        "        # Prepare the new file path\n",
        "        new_file_path = os.path.join(folder_path, new_base_name)\n",
        "\n",
        "        # If the file already exists, append a numeric suffix until it's unique.\n",
        "        count = 1\n",
        "        base_name, ext = os.path.splitext(new_base_name)\n",
        "        while os.path.exists(new_file_path):\n",
        "            new_base_name = f\"{base_name}_{count}{ext}\"\n",
        "            new_file_path = os.path.join(folder_path, new_base_name)\n",
        "            count += 1\n",
        "\n",
        "        try:\n",
        "            os.rename(original_path, new_file_path)\n",
        "            print(f\"Renamed '{filename}' to '{new_base_name}'\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error renaming '{filename}': {e}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}